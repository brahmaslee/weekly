# 业界会议

[**Chrome Dev Summit**](https://developer.chrome.com/devsummit/)
* 时间：2017.10.23-24，地点：San Francisco
* 主题：
   * Modern tooling, testing and automation
   * The future of loading on the web
   * V8 and WebAssembly
   * VR and AR on Web


# 文章阅读

[**Pinterest如何利用机器学习实现两亿月活跃用户**](http://ppt.geekbang.org/qconsh2017)
* Pinterest介绍
   * 2009年成立的互联网初创公司
   * 1300+员工，接近一半是工程师
   * 估值 > 120亿美元
   * 月活跃用户(MAU) > 两亿
* 个性化的灵感分类目录
   * 最基本的信息单位是一张张的图片(pin)
   * 图片来源：用户自行产生并上传至Pinterest, 用户存自网络, 用户从Pinterest转发
   * 图片以瀑布流的方式展现给用户
   * 对每张图片用户可以进行收藏及转发(repin)，点击(clickthrough)或隐藏(hide)等多种操作
   * 对其他用户，图板和许多主题，用户也可以选择关注(follow)
* 成立至今，最主要的产品有四个：
   * 个性化主页 (Homefeed)
   * 搜索 (Search)
   * 相关图片 (Related Pins)
   * 广告 (Ads)
* 最重要的产品：个性化主页
   * 最早大规模使用机器学习的产品
   * 最核心的预测问题：量化给定用户和图片的相关度
   * 每天预测超过2000亿(用户, 图片) 二元组的相关度
   * 相关度预测的优劣，直接影响到Pinterest上活跃用户的数目
* 主页机器学习核心问题
   * 用户-图片相关度预测
      * 特征：用户特征、交互特征、图片特征
      * 目标：为每一位用户预测，该展示哪些来让用户活跃度达到顶点
   * 二元分类的排序问题
      * 训练集的每一个例子：用户和图片的一条交互历史记录
      * 特征向量： 各种描述这条交互历史记录的特征的向量
      * 预测目标值：0或1
      * 我的理解：就是根据用户点赞和不喜欢的图片，来预测任何一张图像是否是用户感兴趣的
* 主页推荐系统简图
   * 候选图片集产生（测试集，数百亿图片中选出数千）
      * 关注的人和图板
      * 关注的兴趣
      * 我们认为你可能喜欢的
   * 机器学习推荐模型（数千图片按相关度排序）
      * 对所有候选图片进行相关度预测
   * 产生主页
      * 保证内容多样化
      * 保证内容新鲜
      * 综合多种来源图片
* 主页推荐模型的进化
   * 2013以前：纯时序排序
   * 2014-15：线性模型，逻辑回归（logistic regression）
      * 最初版本包含12个图片特征以及图片与用户交互信息的特征例如：图片的近期点击率，用户是否曾与图片所在的图板产生过互动
      * 线性模型弊端
         * 线性模型不能很好利用高维度的复杂特征／需要手动添加交叉特征(cross features)
         * 单纯用户方面的特征（例如年龄，性别等）对线性模型无意义
   * 2016：迭代决策树模型， Gradient Boosted Decision Trees (GBDT)
      * 基于决策树的集合模型（ensemble model）
      * 由一系列决策树组成，每一棵决策树都试图减少已生成模型的残差（residual error）
      * 最终相关度预测值为所有决策树预测值的总和
      * 上线的迭代决策树模型
         * 特征数量： 700+
         * 二叉决策树数量： 350 （不同的目标方程）
         * 最大深度： 7 （满二叉树）
         * 训练使用软件：XGBoost
         * 效果: 主页日活跃用户(repinner)增长10%
   * 2017：深度学习模型
* 上线的迭代决策树模型
   * 优点：
      * 1. 非线性模型可以有效的探索和转化特征向量空间
      * 2. 对于单个特征值误差包容度较高
      * 3. 准确高效的特征重要性分析
   * 缺点：
      * 1. 模型参数数量按决策树深度几何级数增长
      * 2. 无法有效利用高维度的稀疏特征
      * 3. 对离散特征的概括性的总结利用不够充分
* 如何有效利用稀疏特征
   * 稀疏特征范例
      * Id特征（图片ID），交叉特征（用户文本特征 图片文本特征）等
   * 1. 将稀疏和非稀疏特征分开
   * 2. 用非稀疏特征产生迭代决策树模型
   * 3. 用决策树的叶子结点产生新的特征向量，然后和(1)里的稀疏特征连接在一起，作为新的特征向量
   * 4. 用逻辑回归来建立最终的预测模型
* 2017年：基于TensorFlow平台的深度学习模型
   * 标准的feed-forward神经网络
   * ～500非稀疏原始特征
   * 一层embedding/标准化层，4层全联接网络，每层数百神经元
   * 训练10% 随机dropout, ReLu神经元，Sigmoid gate神经元
   * 优化目标：加权cross-entropy loss
   * Tensorflow+Keras训练: 单机多GPU
   * 效果: 主页日活跃用户(repinner)增长4%
* 深度学习优势：
   * 更大的模型容量： 深度学习 100万参数 vs GBDT 13万参数
   * 更复杂的特征交互：深度学习全联接层 vs GBDT父子节点关联
   * 更多的非线性关系：深度学习ReLu/Sigmoid/Gate vs GBDT父子节点关联
* 深度学习劣势：
   * 对于原始特征质量要求更高
   * 特征的重要性顺序不清晰，更加黑盒化
   * 训练过程更复杂，耗时较长
* 2014-2017 模型发展总共带来的主页Repinner增长：约40%
* 特征构造的特点
   * 高度特殊化（specialized)
      * 培养公司内部的domain expert
   * 高失败率（多数实验用特征不会上线）
      * 耐心的长期投入，快㏿迭代，缩短实验-上线周期
   * 低透明度：模型可以随便聊，特征一定会保密
      * 总结按产品分类的有效特征，妥善记录经验教训
   * 相对多的体力劳动 （深度学习和embedding会有帮助）
      * 完善特征研发和数据分析平台，减少重复劳动量
   * 有效特征的高回报率
      * 同等对待特征或模型更新带来的收益，建立合理的奖励制度


# 业界特快


[**2017年度开源贡献榜**](http://blog.csdn.net/dev_csdn/article/details/78405746)
* 微软大约有 1,300 名员工积极地将代码推送到 GitHub 上的 825 个顶级仓库。
* 谷歌大约有 900 名员工活跃于 GitHub，将代码推送到约 1,100 个顶级仓库。
* 亚马逊大约有 134 名员工活跃于 GitHub，将代码推送到 仅158 个顶级仓库。


[**V8 Release 6.3**](https://v8project.blogspot.ca/2017/10/v8-release-63.html)

