# 业界会议

[**2017腾讯Live开发者大会**](http://tlc.ivweb.io/?id=weibo)
* 时间：2017.11.04，地点：深圳
* 提升和促进全行业视频、直播、图像处理等领域的交流和技术创新


# 文章阅读


[**Spark App自动化故障分析与诊断**](http://download.csdn.net/meeting/speech_preview/417)
* 苏宁大数据计算平台架构
   * 离线计算，流式计算，OLAP引擎
   * Spark SQL，Spark MLlib，Spark Streaming
* CBT调度平台
   * 为Spark、 Spark SQL、 Hive等离线任务提供任务流的配置、管理以及调度能力
* SSMP平台
   * 针对Spark Streaming提供任务托管、资源托管以及监控报警的能力， 为App 24小时Long Running提供稳定性保证
* 机器学习平台
   * 基于Spark MLlib、 GraphX和Streaming构建的在线机器学习平台，实现模型训练、调优、发布的统一。
* 系统规模
   * 集群规模： Yarn集群700节点；
   * 任务规模： 5W 任务/天；
   * 处理的数据量： 300TB/天；
* Spark平台化过程中，我们遇到很多问题
   * 对Spark SQL的认识不够，导致过度的依赖Spark RDD层面的API
   * 对内存计算存在误解，不合理使用Cache机制，导致资源浪费
   * 不合理的Map、 Reduce并发度设置，导致任务计算效率低，或导致任务调度Overhead过高，并产生过多小文件
   * 平台未提供数据来指导用户去优化Executor个数以及内存参数，导致平台资源利用率过低
* Spark自动化分析和故障诊断
   * Spark任务分析
      * 宿主机状态分析
      * 宿主进程状态分析
      * 资源利用率分析
      * 事件流分析
      * Task耗时链分析
* Druid是一种适用于时序化数据的OLAP分析引擎
   * 特别适合于统计分析、系统监控等业务场景
   * 目前Druid作为主要的OLAP引擎进行推广，支撑销售报表、金融自助分析、风控平台以及平台监控等十多个业务场景。
* 目前提供分析和诊断能力
   * 资源角度
      * 宿主机器状态分析：可以判断任务的性能瓶颈或故障是否与平台稳定性有关
      * HDFS资源使用分析
      * Driver/Executor进程状态分析
      * 资源利用率分析
      * Cache 利用率分析
      * Shuffle内存利用率分析
   * 性能角度
      * Task耗时链分析
      * 长尾Task分析
      * 任务调度Overhead分析
      * Reduce并发度分析
      * JDBC并发度分析Kafka读并发度分析
   * 故障角度
      * Shuffle数据倾斜
      * HDFS Commit阻塞
      * Executor丢失
      * Spill事件分析
      * 高维Parquet写性能诊断
      * RDD Size Estimator
      * 耗时诊断
      * 任务事件流


[**大规模分布式机器学习系统设计和应用经验分享**](http://download.csdn.net/meeting/speech_preview/397)
* 机器学习的经典定义: 利用经验改善系统性能
   * 经验 -> 数据
* 典型的机器学习应用过程（广告点击率预估系统为例）
   * 问题定义： 收入 = 平均每次点击价格 * 点击率 * 广告展现量
   * 应用过程：数据收集->数据预处理->模型训练->模型服务
* 机器学习在工业应用中的发展趋势
   * 数据量的增长：10^4 -> 10^10
   * 特征维度的增长：10^3 (宏观特征) -> 10^10 (微观特征)
   * 宏观特征（比如：年龄、性别等）
   * 长尾特征（比如用户ID等）
* 微观特征 + 复杂模型
   * 摩尔定律失效
      * 能耗墙（Power Wall）
      * 延迟墙（Latency Wall）
   * 单机能力有限
      * IO、存储、计算有限
   * 目前提升计算能力的主流方式
      * 并行化：降低执行延迟提升吞吐
      * 但是， Amdahl定律
* 机器学习算法的 NO FREE LUNCH
   * 任意算法（包括随机算法）在所有问题上的期望性能一样
   * 不存在通用算法
   * 但在具体的实际问题上，有可能存在比其他算法好的算法
* 根据No Free Lunch定理：
   * 实际问题需要很多的尝试
      * 不同的数据
      * 不同的特征表达
      * 不同的模型、模型不同的参数
   * 模型训练是被重复最多的模块* 
   * 没有在所有问题上最好的架构，只有最适合实际问题的
* 需要针对机器学习的兼顾开发效率和执行效率的大规模分布式并行计算框架
   * 提高开发效率：分布式并行模型
   * 典型计算模型：数据流
   * 典型计算模型：参数服务器
   * 趋势：数据流 + 参数服务器
* 执行效率优化举例：计算
   * 均衡
      * 负载均衡（不同机器之间、不同资源之间）
      * 任务分解，异步竞争
   * 单机、分布式分离优化：分布式overhead很大，不能为了分布式而分布式
   * 利用不同硬件的优势：GPU-简单指令，小缓存，粗粒度数据并行；CPU-复杂指令，分支预测，大缓存，任务并行
* 执行效率优化举例：存储
   * 数据本地化
      * 迭代之间数据本地缓存
   * 数据结构优化
      * 数据访问重新排序
      * 调整数据布局（更紧凑的数据结构）
      * 数据预取
* 执行效率优化举例：通讯
   * 通讯模式
      * 点对点：RPC
   * 组通讯
      * Reduce、 Gather、 Scatter
   * 软件优化
      * 序列化框架优化
      * 通讯压缩： CPU和带宽互换
      * 应用层：请求合并、缓存
   * 硬件优化
      * 多网卡
      * Infini-Band
* 执行效率优化举例：容错
   * 选择最适合的Tradeoff
      * 机器学习任务迭代式计算，中间状态多
      * 模型参数是最重要的状态
      * 机器学习训练不需要强一致性
   * Data Lineage vs. Checkpointing
      * Data Lineage (Spark…)：可选择不同粒度
      * Checkpointing(Tensorflow、 MxNet…)：对迭代式的机器学习模型参数和简单的任务状态做粗粒度的Checkpointing
   * 冗余
      * Cold / Warm / Hot Standby
      * Hybrid
* 机器学习实际应用的常见陷阱：一致性
   * 训练/预估一致性
   * 目标含义不一致
   * 字段含义时间一致性：随着时间的推移，某些特征含义会发生变化


# 业界特快


[**最容易就业的职业关键词**](https://twitter.com/peterc/status/914948544745885696)
* 有人分析了 Hacker News 发布的各公司招聘广告，提取里面的关键词，按照出现频率排序，得到了下面的结果 
   * data, python, react, backend, mobile, devops, javascript, ruby, ios, aws
   * machine learning, java, security, docker, go, android, linux
   * financial, marketing, cloud, front end, node, c++, rails, redis, sql, react native
   * postgres, kubernetes, agile, elasticsearch